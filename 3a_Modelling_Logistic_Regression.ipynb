{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the outcome of loan applications\n",
    "# 3a. Logistic regression model\n",
    "For this problem, we care about having a low number of false negatives as possible. False negatives, i.e. people we accept but should have rejected, pose a greater risk, because they could lead to loss of the capital lent as well as potential revenue from the interest. While high recall is associated to few false negatives, we can not tune model parameters by optimising on recall alone, otherwise the model will be pushed to behave like a random model, which has a recall of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "p = os.path.abspath('../')\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)\n",
    "\n",
    "from shared.data_processing import CategoricalEncoder\n",
    "from shared.data_processing import FeatureSelector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/loan_data_prepped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label', 'accepted'], axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the features\n",
    "Features of interest we have identified in the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = ['duration', 'loan_amount', 'age']\n",
    "\n",
    "FIXED_CATEGORICAL = ['foreign_worker_binary', 'checking_status_ordinal', 'savings_status_ordinal',\n",
    "                     'employment_ordinal', 'installment_commitment_ordinal']\n",
    "\n",
    "OTHER_CATEGORICAL = ['loan_history', 'purpose', 'other_parties', 'property_magnitude',\n",
    "                     'other_payment_plans', 'housing', 'personal_status', 'job']\n",
    "\n",
    "FEATURES = NUMERICAL_FEATURES + FIXED_CATEGORICAL + OTHER_CATEGORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['duration',\n",
       " 'loan_amount',\n",
       " 'age',\n",
       " 'foreign_worker_binary',\n",
       " 'checking_status_ordinal',\n",
       " 'savings_status_ordinal',\n",
       " 'employment_ordinal',\n",
       " 'installment_commitment_ordinal',\n",
       " 'loan_history',\n",
       " 'purpose',\n",
       " 'other_parties',\n",
       " 'property_magnitude',\n",
       " 'other_payment_plans',\n",
       " 'housing',\n",
       " 'personal_status',\n",
       " 'job']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model parameters\n",
    "For Logistic Regression, only the regularisation strength needs to be tuned. Given the small size of the data set, I'm using 50 stratified random folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CategoricalEncoder(features_to_encode=OTHER_CATEGORICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = FeatureSelector(features_to_select=NUMERICAL_FEATURES + FIXED_CATEGORICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(max_iter=2000, class_weight='balanced', solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('encode', encoder),\n",
    "                       ('select', selector),\n",
    "                       ('scale', StandardScaler()),\n",
    "                       ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_coarse = {'logistic__C': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]}\n",
    "param_grid_fine = {'logistic__C': np.logspace(0, 2, 20)}\n",
    "param_grid_finest = {'logistic__C': np.logspace(0, 1, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe,\n",
    "                    verbose=1,\n",
    "                    cv=StratifiedKFold(n_splits=50),\n",
    "                    scoring=make_scorer(f1_score),\n",
    "                    param_grid=param_grid_finest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 20 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   55.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=50, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('encode',\n",
       "                                        CategoricalEncoder(features_to_encode=['loan_history',\n",
       "                                                                               'purpose',\n",
       "                                                                               'other_parties',\n",
       "                                                                               'property_magnitude',\n",
       "                                                                               'other_payment_plans',\n",
       "                                                                               'housing',\n",
       "                                                                               'personal_status',\n",
       "                                                                               'job'])),\n",
       "                                       ('select',\n",
       "                                        FeatureSelector(features_to_select=['duration',\n",
       "                                                                            'loan_amount',\n",
       "                                                                            'age',...\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           max_iter=2000,\n",
       "                                                           solver='newton-cg'))]),\n",
       "             param_grid={'logistic__C': array([ 1.        ,  1.12883789,  1.27427499,  1.43844989,  1.62377674,\n",
       "        1.83298071,  2.06913808,  2.33572147,  2.6366509 ,  2.97635144,\n",
       "        3.35981829,  3.79269019,  4.2813324 ,  4.83293024,  5.45559478,\n",
       "        6.15848211,  6.95192796,  7.8475997 ,  8.8586679 , 10.        ])},\n",
       "             scoring=make_scorer(f1_score), verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4384498882876628"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regularisation = grid.best_estimator_.get_params()['logistic__C']\n",
    "best_regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the best model over 50 random splits\n",
    "Given that the data set is so small, it's important to evaluate over many random train/test splits, so that we get a better picture of the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_tuned = LogisticRegression(max_iter=2000,\n",
    "                                    class_weight='balanced',\n",
    "                                    solver='newton-cg',\n",
    "                                    C=best_regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tuned = Pipeline(steps=[('encoder', encoder),\n",
    "                             ('select', selector),\n",
    "                             ('scaler', StandardScaler()),\n",
    "                             ('logistic', logistic_tuned)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=50, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_FUNCTIONS = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1': f1_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {k: [] for k in METRIC_FUNCTIONS.keys()}\n",
    "\n",
    "for train_IDX, test_IDX in sss.split(X, y):\n",
    "    pipe_tuned.fit(X.loc[train_IDX], y.loc[train_IDX])\n",
    "    logistic_predictions = pipe_tuned.predict(X.loc[test_IDX])\n",
    "    truth = y.loc[test_IDX]\n",
    "    \n",
    "    for key, metric in METRIC_FUNCTIONS.items():\n",
    "        METRICS[key].append(metric(truth, logistic_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6472800000000001,\n",
       " 'precision': 0.4409132833860982,\n",
       " 'recall': 0.6469333333333332,\n",
       " 'f1': 0.5235762495915697}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: np.mean(v) for k, v in METRICS.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.02723162866961872,\n",
       " 'precision': 0.02988886000912991,\n",
       " 'recall': 0.05702178920767433,\n",
       " 'f1': 0.03434250281964881}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: np.std(v) for k, v in METRICS.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy on training set to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6533333333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tuned.score(X.loc[train_IDX], y.loc[train_IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
