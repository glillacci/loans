{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the outcome of loan applications\n",
    "# 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('../')\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)\n",
    "\n",
    "from shared.data_processing import CategoricalEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/loan_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recode the label\n",
    "I will re-encode the labels in a more intuitive way where `1` (positive) indicates something that requires human attention, i.e. a rejection, while `0` (negative) suggests that everything is fine, i.e. an acceptance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['accepted'].map({2: 0, 1: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the categorical variables\n",
    "The categorical variables need to be converted to numbers, i.e. ***encoded***, in order to be interpretable by the models. Among the ones we pre-selected in the exploratory data analysis, we distinguish 3 types of categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary categorical variables\n",
    "These are the most straighforward, as they can just be encoded with the two values `0` and `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    963\n",
       "no      37\n",
       "Name: foreign_worker, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['foreign_worker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['foreign_worker_binary'] = df['foreign_worker'].map({'no': 0.0, 'yes': 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal categorical variables\n",
    "These have more than two level, but the levels have an intrinsic ordering. This allows us to encode them using integers which are ordered accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None          394\n",
       "<0DM          274\n",
       "0_to_200DM    269\n",
       ">200DM         63\n",
       "Name: checking_status, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['checking_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['checking_status_ordinal'] = df['checking_status'].map({\n",
    "    'None': -1.0,\n",
    "    '<0DM': 0.0,\n",
    "    '0_to_200DM': 1.0,\n",
    "    '>200DM': 2.0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100DM                        603\n",
       "Unknown_or_no_savings_acct    183\n",
       "100_to_500DM                  103\n",
       "500_to_1000DM                  63\n",
       ">1000DM                        48\n",
       "Name: savings_status, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['savings_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['savings_status_ordinal'] = df['savings_status'].map({\n",
    "    'Unknown_or_no_savings_acct': -1.0,\n",
    "    '<100DM': 0.0,\n",
    "    '100_to_500DM': 1.0,\n",
    "    '500_to_1000DM': 2.0,\n",
    "    '>1000DM': 3.0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1_to_4yrs     339\n",
       ">7yrs         253\n",
       "4_to_7yrs     174\n",
       "<1yr          172\n",
       "unemployed     62\n",
       "Name: employment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['employment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employment_ordinal'] = df['employment'].map({\n",
    "    'unemployed': -1.0,\n",
    "    '<1yr': 0.0, \n",
    "    '1_to_4yrs': 1.0,\n",
    "    '4_to_7yrs' : 2.0,\n",
    "    '>7yrs': 3.0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    476\n",
       "2    231\n",
       "3    157\n",
       "1    136\n",
       "Name: installment_commitment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['installment_commitment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installment commitment is already ordinally encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['installment_commitment_ordinal'] = df['installment_commitment'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data set including the variable with fixed encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change types of all features to float, to prevent warning when scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'int64':\n",
    "        df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/loan_data_prepped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other categorical variables\n",
    "For the others, there is no clear way to associate them to numbers, so we need to find another way. I am going to avoid one-hot encoding for this data set, because it's too small, and we could potentially end up with hundreds of features and only 1000 data points. I will use an encoding based on the effect of the feature on the target. **Since this encoding depends on the target, it needs to be computed using training data only, i.e. separately for each cross-validation fold.** Below is an example using all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER_CATEGORICAL = ['loan_history', 'purpose', 'other_parties', 'property_magnitude',\n",
    "                     'other_payment_plans', 'housing', 'personal_status', 'job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = CategoricalEncoder(features_to_encode=OTHER_CATEGORICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalEncoder(features_to_encode=['loan_history', 'purpose',\n",
       "                                       'other_parties', 'property_magnitude',\n",
       "                                       'other_payment_plans', 'housing',\n",
       "                                       'personal_status', 'job'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(df, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loan_history': {'No_loans_taken_or_all_paid': 0.625,\n",
       "  'All_loans_paid_duly': 0.5714285714285714,\n",
       "  'Existing_loans_paid_till_now': 0.31886792452830187,\n",
       "  'Delay_in_past': 0.3181818181818182,\n",
       "  'Critical_acct_other_loans_existing': 0.17064846416382254},\n",
       " 'purpose': {'education': 0.44,\n",
       "  'other': 0.4166666666666667,\n",
       "  'new_car': 0.3803418803418803,\n",
       "  'repairs': 0.36363636363636365,\n",
       "  'business': 0.35051546391752575,\n",
       "  'domestic_appliances': 0.3333333333333333,\n",
       "  'furniture/equipment': 0.32044198895027626,\n",
       "  'radio/television': 0.22142857142857142,\n",
       "  'used_car': 0.1650485436893204,\n",
       "  'retraining': 0.1111111111111111},\n",
       " 'other_parties': {'co-applicant': 0.43902439024390244,\n",
       "  'None': 0.29988974641675853,\n",
       "  'guarantor': 0.19230769230769232},\n",
       " 'property_magnitude': {'unknown/no_property': 0.43506493506493504,\n",
       "  'car_or_other_nonsavings': 0.3072289156626506,\n",
       "  'building_society_savings_agreement/life_insurance': 0.30603448275862066,\n",
       "  'real_estate': 0.2127659574468085},\n",
       " 'other_payment_plans': {'bank': 0.41007194244604317,\n",
       "  'stores': 0.40425531914893614,\n",
       "  'none': 0.2751842751842752},\n",
       " 'housing': {'for_free': 0.4074074074074074,\n",
       "  'rent': 0.39106145251396646,\n",
       "  'own': 0.2608695652173913},\n",
       " 'personal_status': {'male_divorced/separated': 0.4,\n",
       "  'female_divorced/separated/married': 0.35161290322580646,\n",
       "  'male_married/widowed': 0.2717391304347826,\n",
       "  'male_single': 0.2664233576642336},\n",
       " 'job': {'management_self-employed_highly_qualified/officer': 0.34459459459459457,\n",
       "  'unemployed/unskilled_nonresident': 0.3181818181818182,\n",
       "  'skilled_employee/official': 0.29523809523809524,\n",
       "  'unskilled_resident': 0.28}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enc.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the numerical and encoded categorical features we settled on so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = ['duration', 'loan_amount', 'age']\n",
    "\n",
    "FIXED_CATEGORICAL = ['foreign_worker_binary', 'checking_status_ordinal', 'savings_status_ordinal',\n",
    "                     'employment_ordinal', 'installment_commitment_ordinal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['duration',\n",
       " 'loan_amount',\n",
       " 'age',\n",
       " 'foreign_worker_binary',\n",
       " 'checking_status_ordinal',\n",
       " 'savings_status_ordinal',\n",
       " 'employment_ordinal',\n",
       " 'installment_commitment_ordinal',\n",
       " 'loan_history',\n",
       " 'purpose',\n",
       " 'other_parties',\n",
       " 'property_magnitude',\n",
       " 'other_payment_plans',\n",
       " 'housing',\n",
       " 'personal_status',\n",
       " 'job']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES = NUMERICAL_FEATURES + FIXED_CATEGORICAL + OTHER_CATEGORICAL\n",
    "FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have selected the features manually. But are we sure that we are not using redundant information? We can check this with PCA. It looks like even dropping 1 feature (out of 16) makes the explained variance drop below 99%. Dropping 4 features (out of 16) reduces the explained variance to less than 90%, so overall it seems like using all features is best in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15, svd_solver='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9839873533630258\n",
      "[47.72258167 40.07981394 35.34468598 35.204208   33.76389964 32.07563582\n",
      " 31.68908774 31.25840567 30.3148838  29.92641995 28.925613   27.44199807\n",
      " 26.76892692 24.79109327 22.03937047]\n"
     ]
    }
   ],
   "source": [
    "pca.fit(X_scaled)\n",
    "\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=12, svd_solver='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8704306280739216\n",
      "[47.72258167 40.07981394 35.34468598 35.204208   33.76389964 32.07563582\n",
      " 31.68908774 31.25840567 30.3148838  29.92641995 28.925613   27.44199807]\n"
     ]
    }
   ],
   "source": [
    "pca.fit(X_scaled)\n",
    "\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
